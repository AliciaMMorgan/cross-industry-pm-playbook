# Tool Observations: What Works, What Doesn’t

Over time, I've tested and deployed various AI-powered tools. Here's a summary of observed patterns—beyond the hype.

> 📌 Note: The insights shared in this document are based on personal experience using publicly available generative AI tools across general project and program work. They are not tied to any proprietary system, client engagement, or confidential information. These reflections are intended for educational and exploratory purposes only and apply broadly across industries.


## What Works Well

- **Otter.ai / Zoom AI Companion / Fireflies.ai**
  - Effective for reducing notetaking burden.
  - Summaries enable more strategic participation and follow-ups.
  - Resistance fades when users see summaries help them—not just the manager.

- **ChatGPT / Claude**
  - Great for ideation, drafts, and synthesizing.
  - Must be trained to your context; prompt quality matters.
  - Teams need coaching to move from generic to domain-specific use.

- **Canva AI / Microsoft Designer**
  - Enables faster visual storytelling.
  - Especially helpful for those without design backgrounds.

## What to Watch Out For

- Tools that feel “monitoring-based” (e.g., meeting trackers) need framing.
- Without psychological safety, tool fatigue sets in quickly.
- Implementation without fluency ≠ transformation.

> Observation is a leadership skill. Capture what you see, listen deeply, and use those insights to guide adoption.

